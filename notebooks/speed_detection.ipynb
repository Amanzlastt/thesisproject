{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXoGDPC8xYRk"
      },
      "source": [
        "Speed Detection and Car tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaQBN2aKxYRn",
        "outputId": "7776d265-93c5-4155-f01d-69c63e23dfaf"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append(os.path.abspath(\"../src\"))\n",
        "\n",
        "try :\n",
        "    from tracker import *\n",
        "except ImportError :\n",
        "    print('Import not done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g1t15XsBxYRo"
      },
      "outputs": [],
      "source": [
        "import ultralytics\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from ultralytics import YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vShvVPW8yhmW"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "class Tracker:\n",
        "    def __init__(self):\n",
        "        # Store the center positions of the objects\n",
        "        self.center_points = {}\n",
        "        # Keep the count of the IDs\n",
        "        # each time a new object id detected, the count will increase by one\n",
        "        self.id_count = 0 \n",
        "\n",
        "\n",
        "    def update(self, objects_rect):\n",
        "        # Objects boxes and ids\n",
        "        objects_bbs_ids = []\n",
        "\n",
        "        # Get center point of new object\n",
        "        for rect in objects_rect:\n",
        "            x, y, w, h = rect\n",
        "            cx = (x + x + w) // 2\n",
        "            cy = (y + y + h) // 2\n",
        "\n",
        "            # Find out if that object was detected already\n",
        "            same_object_detected = False\n",
        "            for id, pt in self.center_points.items():\n",
        "                dist = math.hypot(cx - pt[0], cy - pt[1])\n",
        "\n",
        "                if dist < 35:\n",
        "                    self.center_points[id] = (cx, cy)\n",
        "#                    print(self.center_points)\n",
        "                    objects_bbs_ids.append([x, y, w, h, id])\n",
        "                    same_object_detected = True\n",
        "                    break\n",
        "\n",
        "            # New object is detected we assign the ID to that object\n",
        "            if same_object_detected is False:\n",
        "                self.center_points[self.id_count] = (cx, cy)\n",
        "                objects_bbs_ids.append([x, y, w, h, self.id_count])\n",
        "                self.id_count += 1\n",
        "\n",
        "        # Clean the dictionary by center points to remove IDS not used anymore\n",
        "        new_center_points = {}\n",
        "        for obj_bb_id in objects_bbs_ids:\n",
        "            _, _, _, _, object_id = obj_bb_id\n",
        "            center = self.center_points[object_id]\n",
        "            new_center_points[object_id] = center\n",
        "\n",
        "        # Update dictionary with IDs not used removed\n",
        "        self.center_points = new_center_points.copy()\n",
        "        return objects_bbs_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i9KSE_W_xYRq"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8s.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gqB3Oy9GxYRr"
      },
      "outputs": [],
      "source": [
        "class_list = ['person', 'bicycle', 'car','motorcycle', 'airplane', 'bus',\n",
        "              'train', 'truck', 'traffic light']\n",
        "\n",
        "# class_list = ['car','truck']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LGO51nCCxYRs"
      },
      "outputs": [],
      "source": [
        "tracker = Tracker()\n",
        "count = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "down = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dRqcnuIFxYRs"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture('C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\video\\\\highway (1).mp4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 320x640 8 cars, 2 trucks, 367.1ms\n",
            "Speed: 6.2ms preprocess, 367.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 2 trucks, 342.4ms\n",
            "Speed: 0.0ms preprocess, 342.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 cars, 2 trucks, 469.5ms\n",
            "Speed: 0.0ms preprocess, 469.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 cars, 2 trucks, 336.8ms\n",
            "Speed: 0.0ms preprocess, 336.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 2 trucks, 424.6ms\n",
            "Speed: 0.0ms preprocess, 424.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 2 trucks, 588.3ms\n",
            "Speed: 5.8ms preprocess, 588.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 2 trucks, 377.2ms\n",
            "Speed: 3.7ms preprocess, 377.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 2 trucks, 305.5ms\n",
            "Speed: 8.0ms preprocess, 305.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 cars, 2 trucks, 384.6ms\n",
            "Speed: 1.0ms preprocess, 384.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 cars, 2 trucks, 334.9ms\n",
            "Speed: 1.4ms preprocess, 334.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 2 trucks, 292.8ms\n",
            "Speed: 4.5ms preprocess, 292.8ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 1 truck, 357.6ms\n",
            "Speed: 4.9ms preprocess, 357.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 1 truck, 315.2ms\n",
            "Speed: 3.3ms preprocess, 315.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 1 truck, 404.6ms\n",
            "Speed: 4.8ms preprocess, 404.6ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 382.0ms\n",
            "Speed: 9.7ms preprocess, 382.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 306.0ms\n",
            "Speed: 5.5ms preprocess, 306.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 3 trucks, 282.5ms\n",
            "Speed: 10.4ms preprocess, 282.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 1 truck, 283.2ms\n",
            "Speed: 4.3ms preprocess, 283.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 cars, 1 truck, 284.0ms\n",
            "Speed: 3.7ms preprocess, 284.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 1 truck, 284.6ms\n",
            "Speed: 4.0ms preprocess, 284.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 288.8ms\n",
            "Speed: 3.6ms preprocess, 288.8ms inference, 4.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 283.0ms\n",
            "Speed: 3.3ms preprocess, 283.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 1 truck, 283.2ms\n",
            "Speed: 3.0ms preprocess, 283.2ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 2 trucks, 281.1ms\n",
            "Speed: 3.6ms preprocess, 281.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 3 trucks, 298.2ms\n",
            "Speed: 4.3ms preprocess, 298.2ms inference, 1.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 316.8ms\n",
            "Speed: 2.7ms preprocess, 316.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 3 trucks, 287.3ms\n",
            "Speed: 4.1ms preprocess, 287.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 3 trucks, 283.9ms\n",
            "Speed: 3.3ms preprocess, 283.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 3 trucks, 284.0ms\n",
            "Speed: 9.7ms preprocess, 284.0ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 295.1ms\n",
            "Speed: 8.3ms preprocess, 295.1ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 1 truck, 283.8ms\n",
            "Speed: 4.2ms preprocess, 283.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 295.4ms\n",
            "Speed: 10.2ms preprocess, 295.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 1 truck, 386.8ms\n",
            "Speed: 3.0ms preprocess, 386.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 301.4ms\n",
            "Speed: 15.8ms preprocess, 301.4ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 315.5ms\n",
            "Speed: 3.0ms preprocess, 315.5ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 325.8ms\n",
            "Speed: 2.5ms preprocess, 325.8ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 3 trucks, 308.7ms\n",
            "Speed: 7.0ms preprocess, 308.7ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 cars, 2 trucks, 300.6ms\n",
            "Speed: 1.0ms preprocess, 300.6ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 2 trucks, 299.2ms\n",
            "Speed: 6.1ms preprocess, 299.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 2 trucks, 298.7ms\n",
            "Speed: 4.1ms preprocess, 298.7ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 2 trucks, 297.7ms\n",
            "Speed: 4.7ms preprocess, 297.7ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 1 truck, 296.2ms\n",
            "Speed: 15.9ms preprocess, 296.2ms inference, 2.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 cars, 1 truck, 289.3ms\n",
            "Speed: 2.0ms preprocess, 289.3ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 cars, 1 truck, 283.9ms\n",
            "Speed: 3.0ms preprocess, 283.9ms inference, 16.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 cars, 1 truck, 299.1ms\n",
            "Speed: 4.0ms preprocess, 299.1ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 cars, 1 truck, 293.2ms\n",
            "Speed: 1.0ms preprocess, 293.2ms inference, 14.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 cars, 1 truck, 1 bench, 298.9ms\n",
            "Speed: 1.0ms preprocess, 298.9ms inference, 0.0ms postprocess per image at shape (1, 3, 320, 640)\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m     26\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m---> 27\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mclass_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcar\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m c:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mlist\u001b[39m\u001b[38;5;241m.\u001b[39mappend([x1, y1, x2, y2])\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Open the video file\n",
        "cap = cv2.VideoCapture('C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\video\\\\highway (1).mp4')\n",
        "\n",
        "# Get the frames per second (FPS) of the video\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    count += 1\n",
        "    frame = cv2.resize(frame, (1020, 500))\n",
        "\n",
        "    result = model.predict(frame)\n",
        "    a = result[0].boxes.data\n",
        "    a = a.detach().cpu().numpy()\n",
        "    px = pd.DataFrame(a).astype(\"float\")\n",
        "\n",
        "    list = []\n",
        "\n",
        "    for index, row in px.iterrows():\n",
        "        x1 = int(row[0])\n",
        "        x2 = int(row[2])\n",
        "        y1 = int(row[1])\n",
        "        y2 = int(row[3])\n",
        "        d = int(row[5])\n",
        "        c = class_list[d]\n",
        "        if 'car' in c:\n",
        "            list.append([x1, y1, x2, y2])\n",
        "\n",
        "    bbox_id = tracker.update(list)\n",
        "\n",
        "    for bbox in bbox_id:\n",
        "        x3, y3, x4, y4, id = bbox\n",
        "        cx = int(x3 + x4) // 2\n",
        "        cy = int(y3 + y4) // 2\n",
        "\n",
        "        red_line_y = 198\n",
        "        blue_line_y = 268\n",
        "        offset = 7\n",
        "\n",
        "        # Condition for red line\n",
        "        if red_line_y < (cy + offset) and red_line_y > (cy - offset):\n",
        "            down[id] = cy\n",
        "            if id in down:\n",
        "                cv2.circle(frame, (cx, cy), 4, (0, 0, 255), -1)\n",
        "                cv2.putText(frame, str(id), (cx, cy), cv2.FONT_HERSHEY_COMPLEX, 0.8, (0, 255, 255), 2)\n",
        "\n",
        "    text_color = (255, 255, 255)\n",
        "    red_color = (0, 0, 255)\n",
        "    blue_color = (255, 0, 0)\n",
        "    green_color = (0, 255, 0)\n",
        "\n",
        "    cv2.line(frame, (172, 198), (774, 198), red_color, 3)\n",
        "    cv2.putText(frame, ('red line'), (172, 198), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
        "    cv2.line(frame, (8, 268), (927, 268), blue_color, 3)\n",
        "    cv2.putText(frame, ('blue line'), (8, 268), cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1, cv2.LINE_AA)\n",
        "\n",
        "    # Show the frame\n",
        "    cv2.imshow('frames', frame)\n",
        "\n",
        "    # Wait for the appropriate time based on FPS (frame delay in milliseconds)\n",
        "    delay = int(1000 / fps)  # Delay per frame in milliseconds\n",
        "    if cv2.waitKey(delay) & 0xFF == 27:  # ESC key to exit\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_cVe0METxYRt"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
        "cv2.imshow(\"Test Window\", img)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
