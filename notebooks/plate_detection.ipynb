{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c068a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0d72d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"  # Adjust path as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b10f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "img= cv2.imread('C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\car_image\\\\Ethiopia_EV1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1905c807",
   "metadata": {},
   "source": [
    "üîç What is a bilateral filter?\n",
    "A bilateral filter smooths the image like a Gaussian blur but preserves edges, which is crucial when detecting license plates (you want to blur noise but keep edges like letters and borders).\n",
    "\n",
    "d = 11: Diameter of each pixel neighborhood. Larger = more blur.\n",
    "\n",
    "sigmaColor = 17: How much colors can differ before they‚Äôre considered different.\n",
    "\n",
    "Larger value means more colors get blurred together.\n",
    "\n",
    "sigmaSpace = 17: How far pixels can be from the center pixel to influence the result.\n",
    "\n",
    "Larger means a bigger neighborhood is considered for blurring.\n",
    "\n",
    "‚öôÔ∏è These values were chosen experimentally ‚Äî they offer a good balance for removing noise while preserving license plate edges. You can tweak them based on your i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "852384e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Apply bilateral filter (preserves edges better than GaussianBlur)\n",
    "# gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "\n",
    "# # Increase contrast using histogram equalization\n",
    "# gray = cv2.equalizeHist(gray)\n",
    "\n",
    "# # Sharpen image (to counteract blurriness)\n",
    "# kernel = np.array([[0, -1, 0],\n",
    "#                    [-1, 5,-1],\n",
    "#                    [0, -1, 0]])\n",
    "# gray = cv2.filter2D(gray, -1, kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c78735",
   "metadata": {},
   "source": [
    "üîç What does this kernel do?\n",
    "This is a sharpening filter. It emphasizes edges and fine details by subtracting surrounding pixels and boosting the center pixel.\n",
    "\n",
    "üìå How it works:\n",
    "The center value 5 strengthens the current pixel.\n",
    "\n",
    "The surrounding -1 values subtract neighboring pixel values (detecting change).\n",
    "\n",
    "This enhances differences (edges), making text and borders crisper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "07105832",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, 100, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa42ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dc3e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ethiopian_plate(ocr_text):\n",
    "    \"\"\"\n",
    "    Extract structured Ethiopian license plate data.\n",
    "    Format: [digit][Ethiopic Letter][3-6 digits], e.g., 1·äê23456\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'[^0-9\\u1200-\\u137F]', '', ocr_text)\n",
    "\n",
    "    match = re.match(r'(\\d)([\\u1200-\\u137F])(\\d{3,6})', cleaned)\n",
    "    if match:\n",
    "        region, letter, number = match.groups()\n",
    "        return {\n",
    "            \"region_code\": region,\n",
    "            \"letter\": letter,\n",
    "            \"serial_number\": number,\n",
    "            \"formatted\": f\"{region} {letter} {number}\"\n",
    "        }\n",
    "    return {\n",
    "        \"region_code\": None,\n",
    "        \"letter\": None,\n",
    "        \"serial_number\": None,\n",
    "        \"formatted\": cleaned\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19669ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw OCR: (@nB79542A)\n",
      "\n",
      "Extracted Plate: 79542\n"
     ]
    }
   ],
   "source": [
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = w / h\n",
    "\n",
    "    if 2 < aspect_ratio < 6 and w > 100:\n",
    "        plate = img[y:y+h, x:x+w]\n",
    "        ocr_raw = pytesseract.image_to_string(plate, config='--psm 7')\n",
    "\n",
    "        # Process plate format\n",
    "        plate_info = extract_ethiopian_plate(ocr_raw)\n",
    "        print(\"Raw OCR:\", ocr_raw)\n",
    "        print(\"Extracted Plate:\", plate_info[\"formatted\"])\n",
    "\n",
    "        # Draw rectangle and label\n",
    "        cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(img, plate_info[\"formatted\"], (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        plate_found = True\n",
    "        break  # Stop after first valid plate (optional)\n",
    "\n",
    "if not plate_found:\n",
    "    print(\"No plate detected.\")\n",
    "\n",
    "# Show the final image with bounding box and label\n",
    "cv2.imshow(\"Detected Plate\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37712ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw OCR: 6B795421\n",
      "Extracted Plate: 6795421\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import easyocr\n",
    "import re\n",
    "\n",
    "# Initialize EasyOCR with Amharic and English support\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "def extract_ethiopian_plate(ocr_text):\n",
    "    \"\"\"\n",
    "    Extract structured Ethiopian license plate data.\n",
    "    Format: [digit][Ethiopic Letter][3-6 digits], e.g., 1·äê23456\n",
    "    \"\"\"\n",
    "    cleaned = re.sub(r'[^0-9\\u1200-\\u137F]', '', ocr_text)\n",
    "\n",
    "    match = re.match(r'(\\d)([\\u1200-\\u137F])(\\d{3,6})', cleaned)\n",
    "    if match:\n",
    "        region, letter, number = match.groups()\n",
    "        return {\n",
    "            \"region_code\": region,\n",
    "            \"letter\": letter,\n",
    "            \"serial_number\": number,\n",
    "            \"formatted\": f\"{region} {letter} {number}\"\n",
    "        }\n",
    "    return {\n",
    "        \"region_code\": None,\n",
    "        \"letter\": None,\n",
    "        \"serial_number\": None,\n",
    "        \"formatted\": cleaned\n",
    "    }\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(\"C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\car_image\\\\Ethiopia_EV1.jpg\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# # Preprocessing: denoise, enhance contrast, sharpen\n",
    "# gray = cv2.bilateralFilter(gray, 11, 17, 17)\n",
    "# gray = cv2.equalizeHist(gray)\n",
    "# sharpen_kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "# gray = cv2.filter2D(gray, -1, sharpen_kernel)\n",
    "\n",
    "# Edge detection\n",
    "edges = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "# Find contours\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "plate_found = False\n",
    "\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "    aspect_ratio = w / h\n",
    "\n",
    "    if 2 < aspect_ratio < 6 and w > 100:\n",
    "        plate_img = img[y:y+h, x:x+w]\n",
    "\n",
    "        # Resize if too small\n",
    "        if plate_img.shape[1] < 200:\n",
    "            plate_img = cv2.resize(plate_img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        # OCR with EasyOCR\n",
    "        results = reader.readtext(plate_img)\n",
    "\n",
    "        if results:\n",
    "            raw_text = results[0][1]\n",
    "            plate_info = extract_ethiopian_plate(raw_text)\n",
    "            print(\"Raw OCR:\", raw_text)\n",
    "            print(\"Extracted Plate:\", plate_info[\"formatted\"])\n",
    "\n",
    "            # Draw rectangle and label\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            cv2.putText(img, plate_info[\"formatted\"], (x, y - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "            plate_found = True\n",
    "            break\n",
    "\n",
    "if not plate_found:\n",
    "    print(\"No plate detected.\")\n",
    "\n",
    "# Show result\n",
    "cv2.imshow(\"Detected Plate\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
