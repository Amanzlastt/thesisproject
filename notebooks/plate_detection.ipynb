{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d7a8ae",
   "metadata": {},
   "source": [
    "Testing the plate detection model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "451e6605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 C:\\Users\\Aman\\Desktop\\thesisproject\\extracted_frames2\\frame_1200.jpg: 384x640 1 plate, 213.1ms\n",
      "Speed: 0.0ms preprocess, 213.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\model\\\\best (1).pt')  # Update path\n",
    "img_path = 'C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\extracted_frames2\\\\frame_1200.jpg'  # Update path\n",
    "results = model.predict(img_path, conf=0.5, imgsz=640)\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f'Plate {box.conf.item():.2f}', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('output.jpg', img)\n",
    "cv2.imshow('Result', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c936d",
   "metadata": {},
   "source": [
    "preprocessed to increase the performance of the ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ede532",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel '.venv (Python 3.11.9)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "\n",
    "# Initialize EasyOCR reader\n",
    "reader = easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO('C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\model\\\\best (1).pt')\n",
    "\n",
    "# Load image\n",
    "img_path = 'C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\extracted_frames2\\\\frame_1200.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "if img is None:\n",
    "    print(f\"Failed to load image: {img_path}\")\n",
    "    exit()\n",
    "\n",
    "# Predict with YOLOv8\n",
    "results = model.predict(img, conf=0.01, imgsz=640, iou=0.45)\n",
    "print(f\"Number of detected plates: {len(results[0].boxes)}\")\n",
    "\n",
    "# Process detections\n",
    "plate_texts = []\n",
    "for result in results:\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "        conf = box.conf.item()\n",
    "        print(f\"Drawing box: ({x1}, {y1}, {x2}, {y2}), Confidence: {conf:.2f}\")\n",
    "        # Crop plate\n",
    "        plate_img = img[max(0, y1):y2, max(0, x1):x2]\n",
    "        # Preprocess with Laplacian kernel\n",
    "        gray = cv2.cvtColor(plate_img, cv2.COLOR_BGR2GRAY)\n",
    "        upscaled = cv2.resize(gray, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "        laplacian_kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]], dtype=np.float32)\n",
    "        sharpened = cv2.filter2D(upscaled, -1, laplacian_kernel)\n",
    "        # Apply EasyOCR\n",
    "        ocr_results = reader.readtext(sharpened, allowlist='0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ', detail=1)\n",
    "        text = ocr_results[0][1] if ocr_results else \"\"\n",
    "        plate_texts.append(text)\n",
    "        # Draw bounding box and text\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "        cv2.putText(img, f'{text} ({conf:.2f})', (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "# Save and display\n",
    "cv2.imwrite('C:\\\\Users\\\\Aman\\\\Desktop\\\\thesisproject\\\\output_with_text.jpg', img)\n",
    "try:\n",
    "    cv2.imshow('Result', img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "except cv2.error:\n",
    "    print(\"Display failed. Check output_with_text.jpg for bounding boxes.\")\n",
    "print(\"Detected License Plates:\", plate_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9850d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
